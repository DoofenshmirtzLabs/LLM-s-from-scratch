{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccd5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c51bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/894.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/894.9 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 71.7/894.9 kB 653.6 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 92.2/894.9 kB 525.1 kB/s eta 0:00:02\n",
      "   ----- -------------------------------- 133.1/894.9 kB 605.3 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 204.8/894.9 kB 831.5 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 276.5/894.9 kB 947.5 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 358.4/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 358.4/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 358.4/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 358.4/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------- ---------------------- 368.6/894.9 kB 694.6 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 440.3/894.9 kB 786.3 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 481.3/894.9 kB 773.5 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 553.0/894.9 kB 846.7 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 563.2/894.9 kB 803.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 686.1/894.9 kB 882.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 768.0/894.9 kB 950.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 849.9/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 849.9/894.9 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 894.9/894.9 kB 959.5 kB/s eta 0:00:00\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, regex, idna, charset-normalizer, certifi, requests, tiktoken\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 regex-2024.11.6 requests-2.32.3 tiktoken-0.9.0 urllib3-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1addbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e8fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "vocab=tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee59e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d4a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"C:\\\\Users\\\\user\\\\projects\\\\LLM's-from-scratch\\\\data.txt\"\n",
    "text = open(data_dir, 'r',encoding='utf-8').read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631e8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device='cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "print(device)\n",
    "data=torch.tensor(tokenizer.encode(text),dtype=torch.long,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cff2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232724"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a73e26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=16\n",
    "eval_batch_size=8\n",
    "context_length=512\n",
    "train_test_split=0.7\n",
    "\n",
    "n_len=len(data)\n",
    "train_data=data[:int(n_len*train_test_split)]\n",
    "eval_data=data[int(n_len*train_test_split):]\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self,data,batch_size,context_len):\n",
    "        self.tokens=data\n",
    "        self.batch_size=batch_size\n",
    "        self.context_len=context_len\n",
    "        self.current_pos=0\n",
    "    def get_batch(self):\n",
    "        #create input and target labels \"next word perdiction\"\n",
    "        batch_size,context_len=self.batch_size,self.context_len\n",
    "        startpos=self.current_pos\n",
    "        endpos=1+batch_size*context_len\n",
    "        add_tokens=-1\n",
    "        if endpos>len(self.tokens):\n",
    "           \n",
    "            add_tokens=endpos-len(self.tokens)#number of additional tokens required\n",
    "            endpos=len(self.tokens)\n",
    "        d=self.tokens[startpos:endpos]\n",
    "        if add_tokens!=-1:\n",
    "            d=torch.concat(d,self.tokens[:add_tokens])#adding the missing data from front creating an loop on the data\n",
    "        input_tokens=(d[:-1]).view(batch_size,context_len)\n",
    "        target_tokens=d[1:].view(batch_size,context_len)\n",
    "        self.current_pos+=batch_size*context_len\n",
    "        if self.current_pos>len(self.tokens):\n",
    "            self.current_pos=0\n",
    "        return input_tokens,target_tokens\n",
    "train_loader=DataLoader(train_data,train_batch_size,context_length)\n",
    "eval_loader=DataLoader(eval_data,eval_batch_size,context_length)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0927106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens,target_tokens=train_loader.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400e3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512]) torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "print(input_tokens.size(),target_tokens.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f923439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69818\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "d_model=512#size of embeddings\n",
    "n_heads=4#number of heads in multi head attention\n",
    "n_layers=1#number of attention blocks \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init(self,n_heads:int,d_model:int):\n",
    "        super.__init__()\n",
    "\n",
    "        self.d_model=d_model\n",
    "        self.n_heads=n_heads\n",
    "        self.head_dim=d_model//n_heads\n",
    "        assert(self.head_dim*self.heads==self.d_model)\n",
    "        self.query=nn.linear(d_model,d_model)\n",
    "        self.key=nn.linear(d_model,d_model)\n",
    "        self.values=nn.linear(d_model,d_model)\n",
    "        self.fc_out=nn.linear(d_model,d_model)\n",
    "        self.drop_out=nn.Dropout(0.2)\n",
    "    def forward(self,input_tensor:torch.Tensor):\n",
    "        batch_size,seq_len,d_model=input.size()\n",
    "        query=self.query(input_tensor).view(batch_size,seq_len,d_model).permute(0,2,1,3)\n",
    "        key=self.key(input_tensor).view(batch_size,seq_len,d_model).permute(0,2,1,3)\n",
    "        value=self.value(input_tensor).view(batch_size,seq_len,d_model).permute(0,2,1,3)\n",
    "        attention_scores=(torch.matmul(query,key.transpose(-2,-1)))/math.sqrt(d_model)\n",
    "        mask=torch.triu(torch.ones(seq_len,seq_len),diagonal=1).bool().to_device(input_tensor.device)\n",
    "        attention_scores=attention_scores.masked_fill(mask)\n",
    "        attention_weights=torch.softmax(attention_scores,dim=-1)\n",
    "        attention_output=attention_weights.permute(0,2,1,3)\n",
    "        attnetion_output=attention_output.view(batch_size,seq_len,d_model)\n",
    "        output=self.fc_out(attnetion_output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoder(nn.module):\n",
    "    def __init__(self,context_length,d_model):\n",
    "        super.__init__()\n",
    "\n",
    "        self.context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
